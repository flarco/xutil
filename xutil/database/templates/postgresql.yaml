core:
  drop_table: drop table if exists {}
  replace: insert into {table} ({names}) values ({values}) on conflict ({pk_fields}) do update set {set_fields}
  replace_temp: |
    insert into {table} ({names})
    select {names} from {temp_table}
    on conflict ({pk_fields}) do nothing;
    update {table} as t1 set {set_fields2}
    from (select * from {temp_table}) as t2
    where {pk_fields_equal}
  insert_ignore: insert into {table} ({names}) values ({values}) on conflict ({pk_fields}) do nothing
  insert_ignore_temp: insert into {table} ({names}) select {names} from {temp_table} on conflict ({pk_fields}) do nothing
  update_temp: |
    update {table} as t1 set {set_fields2}
    from (select * from {temp_table}) as t2
    where {pk_fields_equal2}
  sample: SELECT {fields} FROM {table} TABLESAMPLE SYSTEM (50) limit {n}
  limit: SELECT {fields} FROM {table} where limit {n}

metadata:
  all_tables: |
    with tables as (
      select
        table_catalog,
        table_schema,
        table_name,
        case table_type
          when 'BASE TABLE' then 'TABLE'
          else table_type
        end as table_type
      from information_schema.tables
    )
    select
      cols.table_schema as schema_name,
      cols.table_name as table_name,
      tables.table_type as table_type,
      count(cols.column_name) as num_columns,
      null::int num_rows,
      null::date last_analyzed
    from information_schema.columns cols
    join tables
      on tables.table_catalog = cols.table_catalog
      and tables.table_schema = cols.table_schema
      and tables.table_name = cols.table_name
      group by cols.table_catalog, cols.table_schema, tables.table_type, cols.table_name
      order by cols.table_catalog, cols.table_schema, cols.table_name

  all_columns: |
    with tables as (
      select
        table_catalog,
        table_schema,
        table_name,
        case table_type
          when 'BASE TABLE' then 'TABLE'
          else table_type
        end as table_type
      from information_schema.tables
    )
    select
      cols.table_schema as schema_name,
      cols.table_name as table_name,
      tables.table_type as table_type,
      cols.column_name as column_name,
      cols.data_type as column_type,
      cols.ordinal_position as column_id,
      null::int num_distinct,
      null::int num_nulls,
      null::int num_rows,
      null::int prct_distinct,
      null::int prct_nulls,
      null::date last_analyzed
    from information_schema.columns cols
    join tables
      on tables.table_catalog = cols.table_catalog
      and tables.table_schema = cols.table_schema
      and tables.table_name = cols.table_name
      order by cols.table_catalog, cols.table_schema, cols.table_name, cols.ordinal_position

analysis:
  field_chars: |
    select
      '{schema}' as schema_nm,
      '{table}' as table_nm,
      '{field}' as field, sum(case when {field}::text ~ '\n' then 1 else 0 end) as cnt_nline, 
      sum(case when {field}::text ~ '\t' then 1 else 0 end) as cnt_tab, 
      sum(case when {field}::text ~ ',' then 1 else 0 end) as cnt_comma, 
      sum(case when {field}::text ~ '"' then 1 else 0 end) as cnt_dquote, 
      min(length({field}::text)) as f_min_len, 
      max(length({field}::text)) as f_max_len
    from {schema}.{table}

  field_stat_deep: |
    select
      '{schema}' as schema_nm,
      '{table}' as table_nm,
      '{field}' as field,
      '{type}' as type,
      count(*) as tot_cnt,
      count({field}) as f_cnt,
      count(*) - count({field}) as f_null_cnt,
      round(100.0 * (count(*) - count({field})) / count(*),1) as f_null_prct,
      count(distinct {field}) as f_dstct_cnt,
      round(100.0 * count(distinct {field}) / count(*),1) as f_dstct_prct,
      count(*) - count(distinct {field}) as f_dup_cnt,
      min({field})::text as f_min,
      max({field})::text as f_max,
      min(length({field}::text)) as f_min_len,
      max(length({field}::text)) as f_max_len
    from {schema}.{table}

  distro_field: |
    with t1 as (
      select
        '{field}'::text as field,
        {field},
        count(1) cnt
      from {schema}.{table}
      group by {field}
      order by count(1) desc
    )
    , t2 as (
      select
        '{field}'::text as field,
        count(1) ttl_cnt
      from {schema}.{table}
    )
    select
      '{table}' as table_nm,
      t1.field,
      {field} as value,
      cnt,
      round(100.0 * cnt / ttl_cnt, 2) as prct
    from t1
    join t2
      on t1.field = t2.field
    order by cnt desc

  distro_field_group: |
    with t1 as (
      select
        '{field}'::text as field,
        {group_expr} as group_exp,
        {field},        
        count(1) cnt
      from {schema}.{table}
      group by {field}, {group_expr}
      order by count(1) desc
    )
    , t2 as (
      select
        '{field}'::text as field,
        count(1) ttl_cnt
      from {schema}.{table}
    )
    select
      '{table}' as table_nm,
      t1.field,
      t1.group_exp,
      {field} as value,
      cnt,
      round(100.0 * cnt / ttl_cnt, 2) as prct
    from t1
    join t2
      on t1.field = t2.field
    order by cnt desc

  distro_field_date: |
    with t1 as (
        select
          '{field}'::text as field,
          extract(year from {field}) as year,
          extract(month from {field}) as month,
          count(1) cnt
        from {schema}.{table}
        group by extract(year from {field}), extract(month from {field})
        order by extract(year from {field}), extract(month from {field})
      )
      , t2 as (
        select '{field}'::text as field, count(1) ttl_cnt
        from {schema}.{table}
      )
      select 
        '{schema}' as schema,
        '{table}' as table,
        t1.field,
        t1.year,
        t1.month,
        cnt,
        round(100.0 * cnt / ttl_cnt, 2) as prct
      from t1
      join t2
        on t1.field = t2.field
      order by t1.year, t1.month

function:
  truncate_f: trunc({field})
  truncate_datef: trunc({field})
  date_to_int: trunc(extract(epoch from {field})/(60*60*24))::int
  number_to_int: round({field}, 0)

# native to general
native_type_map:
  16: "integer"
  # 17:'_bytea'
  # 18:'name'
  18: "string"
  # 19:'_name'
  20: "integer"
  # 21:'int2vector'
  21: "integer"
  # 22:'_int2vector'
  23: "integer"
  # 24:'_regproc'
  25: "string"
  # 26:'oidvector'
  # 26:'_oid'
  # 27:'_tid'
  # 28:'_xid'
  # 29:'_cid'
  # 30:'_oidvector'
  114: "string"
  142: "string"
  # 600:'lseg'
  # 600:'_point'
  # 600:'box'
  # 601:'_lseg'
  # 602:'_path'
  # 603:'_box'
  # 604:'_polygon'
  # 628:'_line'
  # 650:'_cidr'
  700: "float"
  # 701:'point'
  701: "double"
  # 701:'line'
  # 702:'_abstime'
  # 703:'_reltime'
  # 704:'_tinterval'
  # 718:'_circle'
  790: "number"
  # 829:'_macaddr'
  # 869:'_inet'
  # 1033:'_aclitem'
  1042: "string"
  1043: "string"
  1082: "datetime"
  1083: "datetime"
  1114: "datetime"
  1184: "datetime"
  # 1186:'_interval'
  # 1266:'_timetz'
  # 1560:'_bit'
  # 1562:'_varbit'
  1700: "number"
  # 1790:'_refcursor'
  # 2202:'_regprocedure'
  # 2203:'_regoper'
  # 2204:'_regoperator'
  # 2205:'_regclass'
  # 2206:'_regtype'
  # 2249:'_record'
  2275: "string"
  2950: "string"
  # 2970:'_txid_snapshot'
  # 3220:'_pg_lsn'
  # 3614:'_tsvector'
  # 3615:'_tsquery'
  # 3642:'_gtsvector'
  # 3734:'_regconfig'
  # 3769:'_regdictionary'
  3802: "string"
  number: "integer"
  numeric: "decimal"
  text: "string"
  varchar: "string"
  varchar2: "string"
  datetime: "datetime"
  timestamp: "datetime"
  timestamp with time zone: "datetime"

# general to native
general_type_map:
  string: "varchar"
  integer: "integer"
  decimal: "decimal"
  date: "date"
  datetime: "timestamp"
  timestamp: "timestamp"
  text: "text"
